{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/home/a_parida/MantaFlow/manta/tensorflow/tools/\")\n",
    "import uniio\n",
    "import glob\n",
    "import random\n",
    "import scipy.misc\n",
    "import os\n",
    "basePath = 'data/' # path where data is availabe;\n",
    "\n",
    "trainingEpochs = 300\n",
    "batchSize      = 100\n",
    "inSize         = 64 * 64 * 2\n",
    "######################################################\n",
    "# Ex 2.1 – Saving and Loading Training Data\n",
    "#####################################################\n",
    "\n",
    "vel_files= glob.glob('./data/**/*.uni', recursive=True)\n",
    "# load data\n",
    "velocities = []\n",
    "\n",
    "for uniPath in vel_files:\n",
    "    header, content = uniio.readUni(uniPath)# returns [Z,Y,X,C] np array\n",
    "    h = header['dimX']\n",
    "    w  = header['dimY']\n",
    "    arr = content[:, ::-1, :, :-1]  # reverse order of Y axis\n",
    "    arr = np.reshape(arr, [w, h, 2])# discard Z from [Z,Y,X]\n",
    "    velocities.append( arr )\n",
    "\n",
    "loadNum = len(velocities)\n",
    "if loadNum<200:\n",
    "\tprint(\"Error - use at least two full sims, generate data by running 'manta ./manta_genSimSimple.py' a few times...\"); exit(1)\n",
    "\n",
    "velocities = np.reshape( velocities, (len(velocities), 64,64,2) )\n",
    "\n",
    "print(\"Read uni files, total data \" + format(velocities.shape) )\n",
    "valiSize = max(100, int(loadNum * 0.1)) # at least 1 full sim...\n",
    "valiData = velocities[loadNum-valiSize:loadNum,:]\n",
    "velocities  = velocities[0:loadNum-valiSize,:]\n",
    "print(\"Split into %d training and %d validation samples\" % (velocities.shape[0], valiData.shape[0]) )\n",
    "loadNum = velocities.shape[0]\n",
    "\n",
    "############################################################\n",
    "\n",
    "##############################################################\n",
    "# Ex 2.2– First Network Architecture\n",
    "##############################################################\n",
    "\n",
    "def convolution2d(input, biases, weights, strides, padding_kind='SAME'):\n",
    "    input = tf.nn.conv2d(input, weights, strides, padding=padding_kind)\n",
    "    input = tf.nn.bias_add(input, biases)\n",
    "    input = tf.nn.leaky_relu(input)\n",
    "    return input\n",
    "\n",
    "def deconvolution2d(input, weights, biases,outputShape, strides, padding_kind='SAME'):\n",
    "    # needed for dynamic shape with deconvolution\n",
    "    dynamicBatchSize = tf.shape(input)[0]\n",
    "    deconvShape = tf.stack([dynamicBatchSize, outputShape[1], outputShape[2], outputShape[3]])\n",
    "    input = tf.nn.conv2d_transpose(input, weights, deconvShape, strides, padding=padding_kind)\n",
    "    input = tf.nn.bias_add(input, biases)\n",
    "    #print(input.shape)\n",
    "    input = tf.nn.leaky_relu(input)\n",
    "    return input\n",
    "\n",
    "def velocityFieldToPng(frameArray):\n",
    "    \"\"\" Returns an array that can be saved as png with scipy.misc.toimage\n",
    "    from a velocityField with shape [height, width, 2].\"\"\"\n",
    "    outputframeArray = np.zeros((frameArray.shape[0], frameArray.shape[1], 3))\n",
    "    for x in range(frameArray.shape[0]):\n",
    "        for y in range(frameArray.shape[1]):\n",
    "            # values above/below 1/-1 will be truncated by scipy\n",
    "            frameArray[y][x] = (frameArray[y][x] * 0.5) + 0.5\n",
    "            outputframeArray[y][x][0] = frameArray[y][x][0]\n",
    "            outputframeArray[y][x][1] = frameArray[y][x][1]\n",
    "    return outputframeArray\n",
    "\n",
    "# the network structure\n",
    "xIn = tf.placeholder(tf.float32, shape=[None, 64,64, 2])\n",
    "\n",
    "#layer1: Convolution\n",
    "weights1=tf.Variable(tf.random_normal([12,12,2,2], stddev=0.01))#weights==filters\n",
    "#[filter_height, filter_width, in_channels, out_channels]\n",
    "#bias=out_channels\n",
    "bias1=tf.Variable(tf.random_normal([2], stddev=0.01))\n",
    "stride1=[1,2,2,1]\n",
    "out1=convolution2d(xIn,bias1,weights1,stride1)\n",
    "\n",
    "#layer2: Convolution\n",
    "weights2=tf.Variable(tf.random_normal([6,6,2,4], stddev=0.01))#weights==filters\n",
    "#[filter_height, filter_width, in_channels, out_channels]\n",
    "#bias=out_channels\n",
    "bias2=tf.Variable(tf.random_normal([4], stddev=0.01))\n",
    "stride2=[1,4,4,1]\n",
    "out2=convolution2d(out1,bias2,weights2,stride2)\n",
    "\n",
    "#layer3: Convolution\n",
    "weights3=tf.Variable(tf.random_normal([4,4,4,8], stddev=0.01))#weights==filters\n",
    "#[filter_height, filter_width, in_channels, out_channels]\n",
    "#bias=out_channels\n",
    "bias3=tf.Variable(tf.random_normal([8], stddev=0.01))\n",
    "stride3=[1,2,2,1]\n",
    "out3=convolution2d(out2,bias3,weights3,stride3)\n",
    "\n",
    "#layer4: Convolution Get the latentspace\n",
    "weights4=tf.Variable(tf.random_normal([3,3,8,16], stddev=0.01))#weights==filters\n",
    "#[filter_height, filter_width, in_channels, out_channels]\n",
    "#bias=out_channels\n",
    "bias4=tf.Variable(tf.random_normal([16], stddev=0.01))\n",
    "stride4=[1,2,2,1]\n",
    "latentspace=convolution2d(out3,bias4,weights4,stride4)\n",
    "\n",
    "############################################################\n",
    "\n",
    "##############################################################\n",
    "# Ex 2.3– Deconvolutions\n",
    "##############################################################\n",
    "\n",
    "#layer5: DeConvolution from the latentspace\n",
    "weights5=tf.Variable(tf.random_normal([3,3,8,16], stddev=0.01))#weights==filters\n",
    "#[filter_height, filter_width, in_channels, out_channels]\n",
    "#bias=out_channels\n",
    "bias5=tf.Variable(tf.random_normal([8], stddev=0.01))\n",
    "stride5=[1,2,2,1]\n",
    "deconv1=deconvolution2d(latentspace,weights5,bias5,out3.shape,stride5)\n",
    "\n",
    "#layer6: DeConvolution\n",
    "weights6=tf.Variable(tf.random_normal([4,4,4,8], stddev=0.01))#weights==filters\n",
    "#[filter_height, filter_width, in_channels, out_channels]\n",
    "#bias=out_channels\n",
    "bias6=tf.Variable(tf.random_normal([4], stddev=0.01))\n",
    "stride6=[1,2,2,1]\n",
    "deconv2=deconvolution2d(deconv1,weights6,bias6,out2.shape,stride6)\n",
    "\n",
    "#layer7: DeConvolution\n",
    "weights7=tf.Variable(tf.random_normal([6,6,2,4], stddev=0.01))#weights==filters\n",
    "#[filter_height, filter_width, in_channels, out_channels]\n",
    "#bias=out_channels\n",
    "bias7=tf.Variable(tf.random_normal([2], stddev=0.01))\n",
    "stride7=[1,4,4,1]\n",
    "deconv3=deconvolution2d(deconv2,weights7,bias7,out1.shape,stride7)\n",
    "\n",
    "#layer8: DeConvolution\n",
    "weights8=tf.Variable(tf.random_normal([12,12,2,2], stddev=0.01))#weights==filters\n",
    "#[filter_height, filter_width, in_channels, out_channels]\n",
    "#bias=out_channels\n",
    "bias8=tf.Variable(tf.random_normal([2], stddev=0.01))\n",
    "stride8=[1,2,2,1]\n",
    "xOut=deconvolution2d(deconv3,weights8,bias8,xIn.shape,stride8)\n",
    "\n",
    "\n",
    "# cost and Optimistion\n",
    "cost = tf.nn.l2_loss(xIn - xOut)\n",
    "opt  = tf.train.AdamOptimizer(0.0001).minimize(cost)\n",
    "\n",
    "\n",
    "#creating Seesion starting training\n",
    "print(\"Starting training...\")\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# lets train for all epochs\n",
    "for epoch in range(trainingEpochs):\n",
    "\tbatch = []\n",
    "\tfor currNo in range(0, batchSize):\n",
    "\t\tr = random.randint(0, loadNum-1)\n",
    "\t\tbatch.append( velocities[r] )\n",
    "\n",
    "\t_ , currentCost = sess.run([opt, cost], feed_dict={xIn: batch})\n",
    "\tif epoch%10==9 or epoch==trainingEpochs-1:\n",
    "\t\t[valiCost,vout] = sess.run([cost, xOut], feed_dict={xIn: valiData})\n",
    "\t\tprint(\"Epoch %d/%d: cost %f , validation cost %f \" % (epoch, trainingEpochs, currentCost, valiCost) )\n",
    "\n",
    "\t\tif epoch==trainingEpochs-1:\n",
    "\t\t\toutDir = \"./test_simple/AutoEncoder/\"\n",
    "\t\t\tif not os.path.exists(outDir): os.makedirs(outDir)\n",
    "\t\t\tprint(\"\\n Training done. Writing %d images from validation data to directory %s...\" % (len(valiData),outDir) )\n",
    "\t\t\tfor i in range(len(valiData)):\n",
    "\t\t\t\tval_in=velocityFieldToPng(valiData[i])\n",
    "\t\t\t\tval_out=velocityFieldToPng(vout[i])\n",
    "\t\t\t\tscipy.misc.toimage( np.reshape(val_in, [64, 64, 3]) , cmin=0.0, cmax=1.0).save(\"%s/in_%d.png\" % (outDir,i))\n",
    "\t\t\t\tscipy.misc.toimage( np.reshape(val_out, [64, 64, 3]) , cmin=0.0, cmax=1.0).save(\"%s/out_%d.png\" % (outDir,i))\n",
    "\n",
    "print(\"Done...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vel_files= glob.glob('./test*/AutoEncoder/in*', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vel_files2=glob.glob('./test*/Conv*/in*', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(vel_files[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_simple/ConvConvFC/in_54.png\n",
      "./test_simple/AutoEncoder/in_74.png\n"
     ]
    }
   ],
   "source": [
    "for tr in vel_files2:\n",
    "    img2=cv2.imread(tr)\n",
    "    \n",
    "    if np.array_equal(img2, img):\n",
    "        print(tr)\n",
    "        print(vel_files[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
