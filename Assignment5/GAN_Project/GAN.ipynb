{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 64, 64, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data set\n",
    "with open('./data/velocity.pickle', 'rb') as handle:\n",
    "    velocities = pickle.load(handle)\n",
    "\n",
    "velocities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the discriminator\n",
    "\n",
    "def convolution2d(input, biases, weights, strides, padding_kind='SAME'):\n",
    "    input = tf.nn.conv2d(input, weights, [1,strides,strides,1], padding=padding_kind)\n",
    "    input = tf.nn.bias_add(input, biases)\n",
    "    input = tf.nn.leaky_relu(input)\n",
    "    return input\n",
    "\n",
    "def discriminator(x_image):\n",
    "    \n",
    "    #layer1: Convolution\n",
    "    weights1=tf.Variable(tf.random_normal([12,12,2,2], stddev=0.01))\n",
    "    #[filter_height, filter_width, in_channels, out_channels]\n",
    "    #bias=out_channels\n",
    "    bias1=tf.Variable(tf.random_normal([2], stddev=0.01))\n",
    "    stride1=2\n",
    "    out1=convolution2d(x_image,bias1,weights1,stride1)\n",
    "    print(out1.shape)\n",
    "    #layer2: Convolution\n",
    "    weights2=tf.Variable(tf.random_normal([6,6,2,4], stddev=0.01))\n",
    "    bias2=tf.Variable(tf.random_normal([4], stddev=0.01))\n",
    "    stride2=4\n",
    "    out2=convolution2d(out1,bias2,weights2,stride2)\n",
    "    print(out2.shape)\n",
    "    #layer3: Convolution\n",
    "    weights3=tf.Variable(tf.random_normal([4,4,4,8], stddev=0.01))\n",
    "    bias3=tf.Variable(tf.random_normal([8], stddev=0.01))\n",
    "    stride3=2\n",
    "    out3=convolution2d(out2,bias3,weights3,stride3)\n",
    "    print(out3.shape)\n",
    "    #layer4: Convolution\n",
    "    weights4=tf.Variable(tf.random_normal([3,3,8,16], stddev=0.01))#weights==filters\n",
    "    bias4=tf.Variable(tf.random_normal([16], stddev=0.01))\n",
    "    stride4=2\n",
    "    out4=convolution2d(out3,bias4,weights4,stride4)\n",
    "    print(out4.shape)\n",
    "    #layer5: Fully Connected Layer\n",
    "    out4 = tf.reshape(out4, shape=[-1, 64 ]) # flatten\n",
    "    fc_1weights = tf.Variable(tf.random_normal([64, 1], stddev=0.01))\n",
    "    fc_1bias   = tf.Variable(tf.random_normal([1], stddev=0.01))\n",
    "    fc1 = tf.add(tf.matmul(out4, fc_1weights), fc_1bias)\n",
    "    fc1 = tf.nn.tanh(fc1)\n",
    "    \n",
    "    return fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the Generator\n",
    "\n",
    "def deconvolution2d(input, weights, biases,outputShape, strides, padding_kind='SAME',activation='leaky'):\n",
    "    # needed for dynamic shape with deconvolution\n",
    "    dynamicBatchSize = tf.shape(input)[0]\n",
    "    deconvShape = tf.stack([dynamicBatchSize, outputShape[1], outputShape[2], outputShape[3]])\n",
    "    input = tf.nn.conv2d_transpose(input, weights, deconvShape, [1,strides,strides,1], padding=padding_kind)\n",
    "    input = tf.nn.bias_add(input, biases)\n",
    "    if activation =='leaky':\n",
    "        input = tf.nn.leaky_relu(input)\n",
    "    elif activation=='tanh':\n",
    "        input = tf.nn.tanh(input)\n",
    "    return input\n",
    "\n",
    "def generator(noise):\n",
    "    #layer1: DeConvolution\n",
    "    weights5=tf.Variable(tf.random_normal([3,3,8,16], stddev=0.01))#weights==filters\n",
    "    #[filter_height, filter_width, in_channels, out_channels]\n",
    "    #bias=out_channels\n",
    "    bias5=tf.Variable(tf.random_normal([8], stddev=0.01))\n",
    "    stride5=2\n",
    "    deconv1=deconvolution2d(noise,weights5,bias5,[None, 4,4, 8],stride5)\n",
    "\n",
    "    #layer2: DeConvolution\n",
    "    weights6=tf.Variable(tf.random_normal([4,4,4,8], stddev=0.01))#weights==filters\n",
    "    bias6=tf.Variable(tf.random_normal([4], stddev=0.01))\n",
    "    stride6=2\n",
    "    deconv2=deconvolution2d(deconv1,weights6,bias6,[None, 8,8, 4],stride6)\n",
    "\n",
    "    #layer7: DeConvolution\n",
    "    weights7=tf.Variable(tf.random_normal([6,6,2,4], stddev=0.01))#weights==filters\n",
    "    bias7=tf.Variable(tf.random_normal([2], stddev=0.01))\n",
    "    stride7=4\n",
    "    deconv3=deconvolution2d(deconv2,weights7,bias7,[None, 32,32, 2],stride7)\n",
    "\n",
    "    #layer8: DeConvolution\n",
    "    weights8=tf.Variable(tf.random_normal([12,12,2,2], stddev=0.01))#weights==filters\n",
    "    bias8=tf.Variable(tf.random_normal([2], stddev=0.01))\n",
    "    stride8=2\n",
    "    xOut=deconvolution2d(deconv3,weights8,bias8,[None, 64,64, 2],stride8,activation='tanh')# based on GANHacks\n",
    "    \n",
    "    return xOut\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xIn = tf.placeholder(tf.float32, shape=[None, 2,2, 16])\n",
    "#xIn = tf.placeholder(tf.float32, shape=[None, 64,64, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'LeakyRelu_35/Maximum:0' shape=(?, 64, 64, 2) dtype=float32>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#discriminator(xIn)\n",
    "generator(xIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No. Learnable Parameters for the GAN: 1090166\n"
     ]
    }
   ],
   "source": [
    "###Counting the learnable parameters\n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    #print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(\"Total No. Learnable Parameters for the GAN:\",total_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
