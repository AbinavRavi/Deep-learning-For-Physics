{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from Vel2Img import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the high resolution output set\n",
    "with open('./data/velocity64.pickle', 'rb') as handle:\n",
    "    velocities = pickle.load(handle)\n",
    "#normalize the images between -1 and 1\n",
    "for i in range(velocities.shape[0]):\n",
    "    velocities[i,:,:,:]=2*(velocities[i,:,:,:]-velocities[i,:,:,:].min())/(velocities[i,:,:,:].max()-velocities[i,:,:,:].min())-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputImage=np.zeros([10,64,64,3])\n",
    "for i in range(10):\n",
    "    inputImage[i,:,:,:]=scipy.misc.toimage( np.reshape(velocityFieldToPng(velocities[i,:,:,:]), [64, 64, 3]) , cmin=0.0, cmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2,ax3,ax4) = plt.subplots(1, 4)\n",
    "ax1.imshow(inputImage[0,:,:,:])\n",
    "ax2.imshow(inputImage[1,:,:,:])\n",
    "ax3.imshow(inputImage[2,:,:,:])\n",
    "ax4.imshow(inputImage[3,:,:,:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the low resolution input set\n",
    "with open('./data/velocity8.pickle', 'rb') as handle:\n",
    "    velocities8 = pickle.load(handle)\n",
    "#normalize the images between -1 and 1\n",
    "for i in range(velocities8.shape[0]):\n",
    "    velocities8[i,:,:,:]=2*(velocities8[i,:,:,:]-velocities8[i,:,:,:].min())/(velocities8[i,:,:,:].max()-velocities8[i,:,:,:].min())-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputImage8=np.zeros([10,8,8,3])\n",
    "for i in range(10):\n",
    "    inputImage8[i,:,:,:]=scipy.misc.toimage( np.reshape(velocityFieldToPng(velocities8[i,:,:,:]), [8, 8, 3]) , cmin=0.0, cmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2,ax3,ax4) = plt.subplots(1, 4)\n",
    "ax1.imshow(inputImage8[0,:,:,:])\n",
    "ax2.imshow(inputImage8[1,:,:,:])\n",
    "ax3.imshow(inputImage8[2,:,:,:])\n",
    "ax4.imshow(inputImage8[3,:,:,:])\n",
    "#f.title(\"Low Res Input 8x8\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build the discriminator\n",
    "\n",
    "def convolution2d(input, biases, weights, strides, padding_kind='SAME'):\n",
    "    input = tf.nn.conv2d(input, weights, [1,strides,strides,1], padding=padding_kind)\n",
    "    input = tf.nn.bias_add(input, biases)\n",
    "    input = tf.nn.leaky_relu(input)\n",
    "    return input\n",
    "\n",
    "def discriminator(x_image):\n",
    "    \n",
    "    x_image=x_image+tf.random_normal(shape=tf.shape(x_image),mean=0.0, stddev=0.1, dtype=tf.float32)\n",
    "    #layer1: Convolution\n",
    "    weights1=tf.Variable(tf.random_normal([12,12,2,2], stddev=0.01),name='d_Wconv1')\n",
    "    #[filter_height, filter_width, in_channels, out_channels]\n",
    "    #bias=out_channels\n",
    "    bias1=tf.Variable(tf.random_normal([2],stddev=0.01), name='d_Bconv1')\n",
    "    stride1=2\n",
    "    out1=convolution2d(x_image,bias1,weights1,stride1)\n",
    "    print(out1.shape)\n",
    "    #layer2: Convolution\n",
    "    weights2=tf.Variable(tf.random_normal([6,6,2,4], stddev=0.01),name='d_Wconv2')\n",
    "    bias2=tf.Variable(tf.random_normal([4], stddev=0.01),name='d_Bconv2')\n",
    "    stride2=4\n",
    "    out2=convolution2d(out1,bias2,weights2,stride2)\n",
    "    print(out2.shape)\n",
    "    #layer3: Convolution\n",
    "    weights3=tf.Variable(tf.random_normal([4,4,4,8],stddev=0.01), name='d_Wconv3')\n",
    "    bias3=tf.Variable(tf.random_normal([8],stddev=0.01), name='d_Bconv3')\n",
    "    stride3=2\n",
    "    out3=convolution2d(out2,bias3,weights3,stride3)\n",
    "    print(out3.shape)\n",
    "    #layer4: Convolution\n",
    "    weights4=tf.Variable(tf.random_normal([3,3,8,16], stddev=0.01),name='d_Wconv4')#weights==filters\n",
    "    bias4=tf.Variable(tf.random_normal([16], stddev=0.01),name='d_Bconv4')\n",
    "    stride4=2\n",
    "    out4=convolution2d(out3,bias4,weights4,stride4)\n",
    "    print(out4.shape)\n",
    "    #layer5: Fully Connected Layer\n",
    "    out4 = tf.reshape(out4, shape=[-1, 64 ]) # flatten\n",
    "    fc_1weights = tf.Variable(tf.random_normal([64, 1],stddev=0.01), name='d_WFCN1')\n",
    "    fc_1bias   = tf.Variable(tf.random_normal([1], stddev=0.01),name='d_BFCN1')\n",
    "    fc1 = tf.add(tf.matmul(out4, fc_1weights), fc_1bias)\n",
    "    fc1 = tf.nn.sigmoid(fc1)\n",
    "    \n",
    "    '''#layer6: Fully Connected Layer\n",
    "    fc_2weights = tf.Variable(tf.random_normal([8, 1],stddev=0.01), name='d_WFCN2')\n",
    "    fc_2bias   = tf.Variable(tf.random_normal([1], stddev=0.01),name='d_BFCN2')\n",
    "    fc2 = tf.add(tf.matmul(fc1, fc_2weights), fc_1bias)\n",
    "    #fc2 = tf.nn.sigmoid(fc2)'''\n",
    "    \n",
    "    return fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build the Generator\n",
    "\n",
    "def deconvolution2d(input, weights, biases,outputShape, strides, padding_kind='SAME',activation='leaky'):\n",
    "    # needed for dynamic shape with deconvolution\n",
    "    deconvShape = tf.stack([tf.shape(input)[0], strides*tf.shape(input)[1], strides*tf.shape(input)[2], tf.shape(input)[3]])\n",
    "    input = tf.image.resize_images(images=input,\n",
    "    size=tf.stack([strides*tf.shape(input)[1], strides*tf.shape(input)[2]]),method=tf.image.ResizeMethod.BILINEAR)\n",
    "    input=convolution2d(input,biases,weights,1)\n",
    "    return input\n",
    "\n",
    "def generator(noise):\n",
    "    \n",
    "    #layer1: DeConvolution\n",
    "    weights5=tf.Variable(tf.random_normal([6,6,2,256],stddev=0.1), name='g_Wdeconv1')#weights==filters\n",
    "    #[filter_height, filter_width, in_channels, out_channels]\n",
    "    #bias=out_channels\n",
    "    bias5=tf.Variable(tf.random_normal([256], stddev=0.1),name='g_Bdeconv1')\n",
    "    stride5=2#facror of upscale\n",
    "    deconv1=deconvolution2d(noise,weights5,bias5,[None, 16,16, 256],stride5)\n",
    "    print(\"deconv1\",deconv1.shape)\n",
    "    deconv1=tf.nn.dropout(deconv1,0.50)\n",
    "    #layer2: DeConvolution\n",
    "    weights6=tf.Variable(tf.random_normal([6,6,256,128], stddev=0.1),name='g_Wdeconv2')#weights==filters\n",
    "    bias6=tf.Variable(tf.random_normal([128],stddev=0.1), name='g_Bdeconv2')\n",
    "    stride6=1\n",
    "    deconv2=deconvolution2d(deconv1,weights6,bias6,[None, 16,16, 128],stride6)\n",
    "    \n",
    "    #layer3: DeConvolution\n",
    "    weights7=tf.Variable(tf.random_normal([6,6,128,64], stddev=0.1), name='g_Wdeconv3')#weights==filters\n",
    "    bias7=tf.Variable(tf.random_normal([64], stddev=0.1), name='g_Bdeconv3')\n",
    "    stride7=1\n",
    "    deconv3=deconvolution2d(deconv2,weights7,bias7,[None, 16,16, 64],stride7)\n",
    "    #deconv3=tf.nn.dropout(deconv3,0.50)\n",
    "    #layer4: DeConvolution\n",
    "    weights9=tf.Variable(tf.random_normal([6,6,64,32], stddev=0.1),name='g_Wdeconv4')#weights==filters\n",
    "    bias9=tf.Variable(tf.random_normal([32],stddev=0.1), name='g_Bdeconv4')\n",
    "    stride9=2\n",
    "    deconv4=deconvolution2d(deconv3,weights9,bias9,[None, 32,32, 32],stride9)\n",
    "    \n",
    "    #layer5: DeConvolution\n",
    "    weights8=tf.Variable(tf.random_normal([1,1,32,2], stddev=0.1),name='g_Wdeconv5')#weights==filters\n",
    "    bias8=tf.Variable(tf.random_normal([2], stddev=0.1), name='g_Bdeconv5')\n",
    "    stride8=2\n",
    "    xOut=deconvolution2d(deconv4,weights8,bias8,[None, 64,64, 2],stride8,activation='tanh')\n",
    "    \n",
    "    return xOut\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "batch_size = 10\n",
    "sess = tf.Session()\n",
    "ImageInput = tf.placeholder(tf.float32,shape = [None, 64,64, 2])\n",
    "NoiseInput = tf.placeholder(tf.float32,shape=[None, 2,2, 16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 2)\n",
      "(?, 8, 8, 4)\n",
      "(?, 4, 4, 8)\n",
      "(?, 2, 2, 16)\n",
      "(?, 32, 32, 2)\n",
      "(?, 8, 8, 4)\n",
      "(?, 4, 4, 8)\n",
      "(?, 2, 2, 16)\n"
     ]
    }
   ],
   "source": [
    "GeneratedImage = generator(NoiseInput) #GeneratedImage holds the generated images\n",
    "\n",
    "RealImages = discriminator(ImageInput) #holds discriminator outputs (unnormalized) for the real images\n",
    "FakeImages = discriminator(GeneratedImage) #will hold the discriminator output (unnormalized) for generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build Loss\n",
    "Generator_L2Loss= tf.losses.mean_squared_error(labels=ImageInput,predictions=GeneratedImage)\n",
    "Generator_L2LossMetric=tf.reduce_mean(Generator_L2Loss)\n",
    "#Generator_loss = -tf.reduce_mean(tf.log(1.-FakeImages))# the loss function to optimize G is min (log 1-D), but in practice folks practically use max log D\n",
    "Generator_loss  =tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=FakeImages, labels=tf.ones_like(FakeImages)))\n",
    "#Discriminator_loss= -tf.reduce_mean(tf.log(RealImages) + tf.log(1. - FakeImages))\n",
    "#gen_l2_loss = tf.nn.l2_loss(y - gen_part)\n",
    "gen_l1_loss = tf.reduce_mean(tf.abs(ImageInput- GeneratedImage))\n",
    "Generator_loss =Generator_loss +gen_l1_loss#+Generator_L2LossMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=RealImages, labels=tf.ones_like(RealImages)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=FakeImages , labels=tf.zeros_like(FakeImages )))\n",
    "Discriminator_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "#Discriminator_loss=tf.reduce_sum(tf.square(d_out_real-1) + tf.square(Fake))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate each network variables\n",
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate=1e-4\n",
    "# Create the Optimiser\n",
    "optimizer_gen = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimizer_genL2 = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimizer_disc = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "# Create training operations on the repective netork variable only\n",
    "train_gen = optimizer_gen.minimize(Generator_loss, var_list=g_vars)\n",
    "train_genL2 = optimizer_genL2.minimize(Generator_L2Loss, var_list=g_vars)\n",
    "train_disc = optimizer_disc.minimize(Discriminator_loss, var_list=d_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingEpochs=50000\n",
    "preGANtrainingEpochs=1000#0.1*trainingEpochs\n",
    "batchSize= 1000\n",
    "saveFreq=1000\n",
    "loadNum = len(velocities)\n",
    "#creating Seesion starting training\n",
    "print(\"Starting training...\")\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "g_loss_plot=[]\n",
    "d_loss_plot=[]\n",
    "# lets train for all epochs\n",
    "for epoch in range(1,trainingEpochs+1):\n",
    "    batch = []\n",
    "    noise = []\n",
    "    for currNo in range(0, batchSize):\n",
    "        r = random.randint(0, loadNum-1)\n",
    "        batch.append( velocities[r] )\n",
    "        noise.append( velocities8[r] )\n",
    "        \n",
    "    # Generate noise to feed to the generator\n",
    "    z = noise\n",
    "    \n",
    "    if epoch<preGANtrainingEpochs:\n",
    "        # Train L2\n",
    "        fed_dict={ImageInput: batch, NoiseInput: z}\n",
    "        _, gl=sess.run([train_genL2,Generator_L2LossMetric],feed_dict=fed_dict)\n",
    "        if epoch % 100 == 0 or epoch == 1:\n",
    "            print('Epoch %i: Generator Loss: %f' % (epoch, gl))\n",
    "    else:\n",
    "        # Train Adversierial\n",
    "        fed_dict = {ImageInput: batch, NoiseInput: z,epNo:epoch}\n",
    "        t,_, _, gl, dl = sess.run([GeneratedImage,train_gen, train_disc, Generator_loss, Discriminator_loss],\n",
    "                                    feed_dict=fed_dict)\n",
    "\n",
    "        if epoch % saveFreq == 0 or epoch == 1:\n",
    "            print('Epoch %i: Generator Loss: %f, Discriminator Loss: %f' % (epoch, gl, dl))\n",
    "            g_loss_plot.append(gl)\n",
    "            d_loss_plot.append(dl)\n",
    "            outDir = \"./Progress/\"\n",
    "            if not os.path.exists(outDir): \n",
    "                os.makedirs(outDir)   \n",
    "            r = random.randint(0, batchSize-1)\n",
    "            #scipy.misc.toimage(np.reshape(z[r,:,:,:],(8,8)) , cmin=0.0, cmax=1.0).save(\"%s/noise_%d.png\" % (outDir,epoch))\n",
    "           # g = sess.run([GeneratedImage], feed_dict={NoiseInput:z[r:r+1,:,:,:] })\n",
    "            g = np.reshape(t[r], newshape=( 64, 64, 2))\n",
    "            generatedImage=velocityFieldToPng(g)\n",
    "\n",
    "            scipy.misc.toimage( np.reshape(generatedImage, [64, 64, 3]) , cmin=0.0, cmax=1.0).save(outDir+'/genImg_'+str(epoch).zfill(len(str(trainingEpochs))) +'.png')\n",
    "\n",
    "print(\"Done...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.plot(np.arange(0,trainingEpochs-preGANtrainingEpochs,saveFreq), np.array(g_loss_plot)[1:])\n",
    "plt.title('GAN: Generator Loss')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(np.arange(0,trainingEpochs-preGANtrainingEpochs,saveFreq), np.array(d_loss_plot)[:-1])\n",
    "plt.title('GAN: Discriminator Loss')\n",
    "plt.show()\n",
    "#plt.savefig('./Result/losses.svg')\n",
    "#plt.savefig('losses.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No. Learnable Parameters for the GAN: 2579968\n"
     ]
    }
   ],
   "source": [
    "###Counting the learnable parameters\n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    #print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(\"Total No. Learnable Parameters for the GAN:\",total_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
